<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8"/>
    <title>Probability Distributions</title>
    <link rel="stylesheet" href="tufte.min.css"/>
    <style>
      .katex { font-size: 0.95em !important; }
      foreignObject { font-size: 2em; }
    </style>
    <!-- local D3 -->
    <script type="text/javascript" src="d3.min.js" charset="utf-8"></script>
    <!-- fetch D3 -->
    <!-- <script src="https://d3js.org/d3.v5.min.js"></script> -->

    <!-- local KaTeX -->
    <link defer rel="stylesheet" href="katex.min.css">
    <script defer src="katex.min.js" charset="uft-8"></script>
    <script defer src="auto-render.min.js" charset="utf-8" onload="renderMathInElement(document.body);"></script>
    <!-- fetch KaTeX-->
    <!--   <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous"> -->
    <!-- <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script> -->
    <!-- <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script> -->

    <!-- local jStat -->
    <script type="text/javascript" src="jstat.min.js"></script>
    <!-- fetch jStat -->
    <!-- <script src="https://cdn.jsdelivr.net/npm/jstat@latest/dist/jstat.min.js"></script> -->

    <meta name="viewport" content="width=device-width, initial-scale=1">
  </head>
  <body>
    <article>
      <h1 id="page">Probability Distributions</h1>
      <p class="subtitle">Edward A. Roualdes</p>
      <p class="subtitle">December 2020</p>
      <section>
        <h2 id="contents">Contents</h2>
        <bold><a href="#introduction">Introduction</a></bold></br>
      </section>

      <section>
        <h2 id="introduction">Introduction</h2>
        <p>
          TODO clean up thinking out loud.  A probability distribution
          is a function that assigns probability to some
          subsets<span class="marginnote">Only measurable subsets of
          the space \( \mathsf{S} \) are assigned probability.  See
          section <a href="https://stats.libretexts.org/Bookshelves/Probability_Theory/Book%3A_Probability_Mathematical_Statistics_and_Stochastic_Processes_(Siegrist)/01%3A_Foundations/1.11%3A_Measurable_Spaces">Measurable
          Spaces</a> in Kyle
          Siegrist's <a href="https://en.wikipedia.org/wiki/Open_educational_resources">OER</a> <a href="https://stats.libretexts.org/Bookshelves/Probability_Theory/Book%3A_Probability_Mathematical_Statistics_and_Stochastic_Processes_(Siegrist)">book</a>.</span>
          of a set \( \mathsf{S} \) via a function denoted \(
          \mathbb{P} \).  Denote \( \mathcal{S} \) as the set of sets
          that are assigned probability.  Then \( \mathbb{P}[A] \)
          takes on a real number in \( [0, 1] \) for every \( A \in
          \mathcal{S} \).  Probability distributions are thus set
          functions, \( \mathbb{P}: \mathcal{S} \rightarrow [0, 1] \).
          A probability distribution can be represented in a number of
          different forms.  The two most common representations are
          distribution functions or density functions.
        </p>

        <p>
          Axioms of probability.
        </p>

        <p>
            Probability distributions are rather vague because they
            are so abstract.  So long as \( \mathbb{P} \) maps
            appropriate sets in \( \mathcal{S} \) to real numbers in
            the interval \( [0, 1] \), such that the axioms of
            probability are satisfied, then all is well
            mathematically.  However, in practice this can leave much
            to be desired.  In example, aside from simple examples
            where \( \mathsf{S} = \{0, 1\} \), it's not easy to
            specify all the way in which a probability distribution
            might actually map appropriate sets in \( \mathcal{S} \)
            to real numbers in \( [0, 1] \).
        </p>

        <p>
            Often statisticians resort to implicitly assuming that a
            density function representation exists and then proceed to
            characterize the probability distribution itself via
            expected values of some choice functions.  In these
            settings, it's only through the expected values that
            statisticians interpret probability distributions.
        </p>

        <p>
            Below I provide the classic example of a family of
            probability distirbutions defined with respect to the set
            \( \mathsf{S} = \{0, 1\} \), and use this example to
            provide a tangible example to the more general language
            that follows.  After this example, I provide TODO (what am
            I saying?) some general topics, each of which will require
            further reading.  Links are provided to the topics beyond
            the scope of this page.
        </p>

        <p>
            Topics beyond the scope of this page: introduction to
            probability (which should maybe be renamed to arithmetic
            of probability or some such title that doesn't so easily
            conflate with this page), distribution functions, density
            functions, and specific density functions.
        </p>

        <section>
            <h2 id="bernoulli">Family of Bernoulli Distributions</h2>

            Small example that links to Bernoulli Distribution page
            and highlights: \( \mathsf{S} = \{0,1\} \), density
            function (in this case) corresponds the probability
            distribution, distribution function.
        </section>

        <section>
            <h2 id="distributionfunction">Distribution Functions</h2>

            <p>
                Distribution functions <span class="marginnote">Distribution functions
                are also known as cumulative distribution functions.</span>
                are defined as TODO probably need to say something
                about only univariate distributions here.

                \[ F(x) = \int_{\mathsf{X}}
                \mathbb{I}_{[\mathsf{X}_{\min}, x]}(t) \mathbb{P}[dt]
                \]

                where the notation \( \mathsf{X}_{\min} \) is meant to
                capture the lower limit of the set \( \mathsf{X} \),
                which could be \( -\infty \), \( 0 \), some \( a \in
                \mathbb{R}^+\).
            </p>

            <p>
                TODO Probably need to say something about density
                functions only sometimes existing.  And see below for
                a more common definition of distribution functions,
                namely when the density function exists.
            </p>
        </section>

        <section>
            <h2 id="densityfunction">Density Functions</h2>

        <p>
          A density function is the derivative of the distribution
          function, for some specific probability
          distributon.<span class="marginnote">Density functions have
          a slew of alternative names ranging from incredibly
          specific, probability mass function when \( \mathsf{X} \)
          is countable or probability density function when \(
          \mathsf{X} \) is uncountable, or even just density, when
          interested in brevity.</span>  When the probability
          distribution is absolutely continuous with respect to a
          reference measure \( \mu \), then there exists a function \(
          f : \mathsf{X} \rightarrow \mathbb{R} \), known as the
          density function relative to a measure \( \nu \), defined on
          the same space as \( \mu \), such that

          \[ \nu[A] = \int_A f d\mu \]

          for all \( A \in \mathcal{X} \).  When \( f \) exists, then
          we can define a distribution function from
          it<span class="marginnote">The fact that a distribution
          function can be written two different ways is a source of
          much confusion about the existence of density
          functions.</span>.  A distribution function can be defined
          as

          \[ F(x) = \mathbb{E}_f[\mathbb{I}_{[\mathsf{X}_{min}, x]}] \]
        </p>

        <p>
          By going with \( \mathbb{E}_f \), I'm also bucking the trend
          to annotate \( \mathbb{E} \) with the distribution function,
          \( F \).  I should at least have side note admitting that
          this notation is not common, and at times meaningless (like
          when densities don't exist).  On the other hand, it's not
          always clear how \( \mathbb{E}_F \) is to be calculated when
          the density of \( F \) does not exist.  So really, I'm just
          acknowledging in my notation that we are primarily
          interested in expectations that have more obviously
            calculable representations.
        </p>

        <p>
            On the other hand,

            \[ F(x) = \mathbb{E}_{F}[\mathbb{I}_{[\mathsf{X}_{min}, x]}] \]

            is really rather circular.
        </p>

        <p>
          When density \( f \) does exist, we tend to think about it
          as being indexed by a parameter \( \theta \in \Theta \subset
          \mathbb{R} \), thus giving us a family of density functions.
          Given our discussion above, that density functions
          technically are derived as derivatives of distribution
          functions, which themselves derive from probability
          distributions, there is really a family of probability
          distributions, which give rise to a family of density
          functions.

          \[ \mathbb{P}_{\theta}, F_{\theta}, f_{\theta}, \mathcal{S} \]
        </p>

        <p>
          END thinking out loud.
        </p>

      </section>

      <section>
        <h2 id="uniform">Family of Discrete Uniform Distribution</h2>

        <p>
          Before we get to a more theoretical treatment of
          probability, let's introduce the notation of probability.
          Syntactically, probability works like a function.  We'll use
          the bold, capital letter p, \( \mathbb{P} \).
        </p>

        <p>
          A probability function \( \mathbb{P} \) acts on sets, called
          events in statistics, instead of numbers like you're
          probably used to.  Hence, probability is a set
          function.<span class="marginnote">Here's a refresher
          on <a href="lecturenotes/sets.html">sets and set theory</a>,
          in case you want it.</span> A function \( \mathbb{P} \)
          acts on sets and returns a real number guaranteed to be in
          the set \( [0, 1]
          \).<span class="marginnote">Mathematically, we'd write \(
          \mathbb{P}: S \rightarrow [0, 1] \)</span>
        </p>

        <p>
          Notice that we have yet to specify how a function \(
          \mathbb{P} \) maps sets to real numbers between \( 0 \) and
          \(1 \).  So far, we've just said that it does this.  In
          fact, the way a function \( \mathbb{P} \) maps sets to real
          numbers between \( 0 \) and \( 1 \) can be quite complex.
          Specifying more complex examples of \( \mathbb{P} \)  will be
          discussed in greater detail under the topic of probability
          distributions.  For now, let's consider a case of \(
          \mathbb{P} \) specified on finite sets.
        </p>

        <p>
          Consider the set \( S = \{1, 2, 3, 4, 5, 6\} \) and \( A =
          \{2, 4, 6 \} \) a susbet of \( S \).  We seek to define a
          set function that produces the probability \( 1/2 \) when
          applied to \( A \), \( \mathbb{P}[A] = 1/2 \).  We'd also
          like this same set function to be more general, such that it
          produces similarly intuitive results for other subsets of \(
          S \).
        </p>

        <p>
          Luckily, since \( S \) is finite, a relatively simple
          solution works here.  Put \( \mathbb{P} \) to be the set
          function that maps arbitrary sets \( B \subset S \) to the fraction

          \[ \mathbb{P}[B] = \frac{|B|}{|S|}. \]

          Recall from the notes on <a href="sets.html">Basic Set
          Theory</a> that the cardinality \( | \cdot | \) of a finite
          set counts the elements.  Thus, if we applied this set
          function to \( A \subset S \), we'd get \( \mathbb{P}[A] =
          3/6 = 1/2 \), as desired.  With this more general definition
          of \( \mathbb{P} \) applied to finite sets, we will hence
          forward refer to it as a probability
          distribution.<span class="marginnote">Such functions \(
          \mathbb{P} \) are referred to as probability distributions
          because they distribute probability across subsets of the
          set \( S \) on which they act.</span>
        </p>

        <p>
          The probability distribution above also yields other
          intuitive results.  For instance, \( \mathbb{P}[\{1\}] = 1/6
          \).  Or more generally, \( \mathbb{P}[\{s\}] = 1/6 \) for
          any single element \(s \in S \).  This is the same logic
          that yields equal probabilities and thus fairness in a coin,
          a die, or a standard deck of cards.
        </p>

        <p>
          There are other ways one could distribute probability across
          a set \( S \) than what is defined above.  The specific
          choice above yields intuitive results, but is not otherwise
          special.  You could, for instance, define your own
          probability distribution that assigns unequal weights to the
          two sides of a coin.
        </p>

        <p>
          We'll defer discussion about more complex versions of \(
          \mathbb{P} \) until the notes Probability Distributions.
          Below, we describe some general properties of arbitrary
          probability distributions.  The three axioms of probability
          are what separate general set functions from probability
          distributions.  As an exercise throughout the next section,
          verify that our probability distribution defined above meets
          all the axioms of probability.
        </p>

      </section>



      <hr>
      <a href="https://creativecommons.org/licenses/by-nc-sa/4.0">
        Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International
      </a>
    </article>

    <script type="text/javascript">
    </script>
  </body>
</html>
